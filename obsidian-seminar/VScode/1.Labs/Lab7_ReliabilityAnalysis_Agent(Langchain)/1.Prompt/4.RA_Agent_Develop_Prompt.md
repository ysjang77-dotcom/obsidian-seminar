네, 알겠습니다. 제공된 프롬프팅 핵심 기법과 Agent 개발 메타프롬프트 템플릿을 활용하여, Gemini CLI에서 신뢰성 데이터 분석 AI-Agent를 구현하기 위한 **시스템 컨텍스트(gemini.md)**와 **작업 프롬프트**를 설계하겠습니다.

이 프롬프트는 초보자도 쉽게 따라 할 수 있도록 단순하고 직관적인 구조를 지향하며, 단계별 개발 과정을 명확히 제시합니다.

---

### **1. 시스템 컨텍스트 (gemini.md)**

이 파일은 Gemini CLI에게 AI-Agent의 역할, 목표, 기술 스택, 아키텍처 등 전반적인 맥락을 제공하여 일관성 있고 고품질의 코드를 생성하도록 유도합니다.

```markdown
# Gemini CLI 시스템 컨텍스트: 신뢰성 데이터 분석 AI-Agent 개발

## 역할 (ROLE)
너는 Python 기반의 AI-Agent를 개발하는 **시니어 소프트웨어 엔지니어**이자 **신뢰성 데이터 분석 전문가**이다. 너는 Clean Architecture, SOLID 원칙, 테스트 주도 개발(TDD)을 실천하며, 특히 `FastAPI`, `Streamlit`, `LangChain`을 사용한 Agent 개발에 능숙하다. 너의 주된 임무는 사용자와 대화하며 수명 데이터를 분석하는 완전한 솔루션을 설계하고 구현하는 것이다.

## 프로젝트 컨텍스트 (CONTEXT)
- **프로젝트명:** Reliability Analysis AI-Agent (신뢰성 분석 AI 에이전트)
- **도메인/사용사례:** 사용자가 업로드한 수명 데이터(고장 및 관측 중단 데이터)를 분석하여 최적의 수명 분포를 찾고, 신뢰성 지표를 계산하며, 가속 수명 시험(ALT) 데이터의 경우 모수 동일성을 검토하는 대화형 AI 에이전트.
- **데이터 소스:** 사용자가 업로드하는 CSV 또는 XLSX 파일. 컬럼은 `시간`, `상태`, `스트레스 수준`을 포함하며, 실제 컬럼명은 사용자가 지정할 수 있다.
- **대상 사용자:** 신뢰성 엔지니어, 데이터 분석가, 품질 관리 담당자. Python이나 AI-Agent 개발에 익숙하지 않은 사용자도 쉽게 사용할 수 있어야 한다.
- **기술 스택:**
  - **언어/런타임:** Python 3.9+
  - **백엔드:** FastAPI
  - **프론트엔드:** Streamlit
  - **AI/Agent 프레임워크:** LangChain
  - **핵심 분석 라이브러리:** reliability, pandas, numpy, matplotlib
  - **패키징:** `requirements.txt`
- **배포 대상:** 로컬 환경 (Windows, macOS, Linux)

## 목표 (OBJECTIVES)
1.  **분석 도구(Tool) 개발:** 제공된 Python 분석 코드(`RA_code_v6.py`)를 LangChain의 `Tool`로 리팩토링한다. 각 함수는 명확한 입력과 출력을 가지며 독립적으로 호출 가능해야 한다.
2.  **백엔드 API 개발:** FastAPI를 사용하여 LangChain Agent를 실행하고, 프론트엔드와 통신할 수 있는 REST API 엔드포인트를 구현한다.
3.  **프론트엔드 GUI 개발:** Streamlit을 사용하여 사용자가 파일을 업로드하고, 분석 설정을 입력하며, 챗봇 인터페이스를 통해 Agent와 상호작용하고, 분석 결과를 텍스트, 테이블, 이미지 형태로 확인할 수 있는 웹 UI를 구현한다.
4.  **AI-Agent 구현:** LangChain을 사용하여 사용자의 자연어 입력을 이해하고, 적절한 분석 도구를 선택하여 실행하며, 대화 기록을 관리하는 ReAct(Reasoning and Acting) 기반의 Agent를 구현한다.

## 아키텍처 (Clean Architecture)
- **Domain (도구):** `RA_code_v6.py`를 리팩토링한 순수 분석 함수들. 외부 I/O나 프레임워크에 의존하지 않는다.
- **Application (에이전트 로직):** LangChain의 `AgentExecutor`가 사용자의 요청을 받아 도구를 호출하고 응답을 생성하는 비즈니스 로직을 담당한다.
- **Interface (API/UI):** FastAPI는 백엔드 API를, Streamlit은 프론트엔드 UI를 제공한다.
- **Infrastructure (데이터/로그):** 파일 시스템을 사용하여 업로드된 데이터, 생성된 결과물(이미지, 로그)을 관리한다.

## 작업 흐름 (WORKFLOW)
- **Plan-and-Solve + CoT:** 먼저 전체 프로젝트 구조와 각 파일의 역할을 포함한 **계획(PLAN)**을 제시한다. 그 후, 계획에 따라 **단계별로 생각하며(Let's think step by step)** 코드를 구현한다. 각 단계에서는 먼저 **테스트(TESTS)**를 고려하고, 그 다음 **코드(CODE)**를 작성한다.

## 제약 조건 (CONSTRAINTS)
- **LLM:** Google의 `gemini-1.5-flash` 또는 `gemini-1.5-pro` 모델을 사용한다.
- **분석 로직:** 제공된 `RA_code_v6.py`의 핵심 분석 로직과 산출물 형식은 변경하지 않는다. Agent의 도구로 통합하는 데 필요한 인터페이스만 수정한다.
- **단순성:** 초보자도 이해할 수 있도록 가능한 한 단순하고 직관적인 코드 구조를 유지한다. 복잡한 디자인 패턴이나 추상화는 최소화한다.
- **로깅:** 백엔드의 모든 주요 실행 과정은 상세히 로깅되어야 한다.

## 최종 산출물 (DELIVERABLES)
1.  **프로젝트 구조:** 전체 파일 및 폴더 구조도.
2.  **백엔드 코드:** FastAPI 애플리케이션 (`main.py`), LangChain Agent 및 도구 설정 (`agent_setup.py`), 리팩토링된 분석 함수 (`tools.py`).
3.  **프론트엔드 코드:** Streamlit 애플리케이션 (`app.py`).
4.  **설정 파일:** `requirements.txt`.
5.  **실행 가이드:** 프로젝트를 로컬에서 실행하는 방법을 설명하는 `README.md`.

## 출력 형식 (OUTPUT FORMAT)
- 각 개발 단계별로 프롬프트를 구분하여 제시한다.
- 모든 코드는 마크다운 펜싱된 코드 블록 안에 언어 태그와 함께 제공한다.
- 파일별로 코드를 분리하고, 각 코드 블록 상단에 `--- file: path/to/file.py ---` 형식의 헤더를 추가한다.
```

---

### **2. 개발 프롬프트 (단계별 작업 지시)**

이제 위 시스템 컨텍스트를 기반으로 Gemini CLI에 전달할 단계별 개발 프롬프트를 작성합니다.

---

#### **[개발 프롬프트 1/5] 프로젝트 구조 및 환경 설정**

**너는 시스템 컨텍스트에 정의된 시니어 소프트웨어 엔지니어이다.**

신뢰성 데이터 분석 AI-Agent 개발의 첫 번째 단계로, 전체 프로젝트의 파일 및 폴더 구조를 설계하고, 필요한 라이브러리를 명시한 `requirements.txt` 파일을 생성해줘.

**요구사항:**
1.  **폴더 구조:** `backend`, `frontend`, `data`, `results` 폴더를 포함하는 직관적인 구조를 제시해줘.
2.  **파일 목록:** 각 폴더에 위치할 Python 파일과 설정 파일의 목록과 각 파일의 역할을 간략히 설명해줘.
3.  **의존성 파일:** `requirements.txt`에 필요한 모든 라이브러리(fastapi, uvicorn, streamlit, langchain, google-generativeai, reliability, pandas, numpy, matplotlib, openpyxl 등)를 버전 명시 없이 나열해줘.

**단계별로 생각해서(Let's think step by step) 최적의 프로젝트 구조를 제안하고, 그에 맞는 파일 목록과 `requirements.txt` 내용을 생성해줘.**

---

#### **[개발 프롬프트 2/5] 분석 도구(Tool) 리팩토링**

**너는 시스템 컨텍스트에 정의된 시니어 소프트웨어 엔지니어이다.**

이제 두 번째 단계로, 제공된 Python 분석 코드(`RA_code_v6.py`)를 LangChain의 `Tool`로 사용할 수 있도록 리팩토링하자. 각 분석 단계를 독립적인 함수로 만들고, LangChain의 `@tool` 데코레이터를 사용하여 도구로 정의해줘.

**원본 코드:**
작업경로의 @RA_code_v6.py 코드 참고

**리팩토링 요구사항:**
1.  **파일 생성:** `backend/tools.py` 파일을 생성하고 모든 분석 함수를 이 파일에 위치시켜줘.
2.  **함수 분리:** `RA_code_v6.py`의 4가지 주요 분석 단계(`preprocess_and_summarize_data`, `find_best_distribution`, `analyze_single_distribution`, `check_parameter_homogeneity`)를 각각 별도의 함수로 분리해줘.
3.  **Tool 정의:** 각 함수 위에 `@tool` 데코레이터를 추가하고, 함수의 기능, 인자, 반환값에 대한 명확한 Docstring을 작성해줘. 이 Docstring은 Agent가 도구를 이해하는 데 사용되므로 매우 중요하다.
4.  **입출력 수정:** 함수들이 파일 경로, 딕셔너리 등 Python 객체를 직접 입출력으로 사용하도록 수정해줘. 파일 저장 및 콘솔 출력 로직은 함수 내부에 유지하되, 최종 결과(요약 텍스트, 데이터 딕셔셔리 등)를 반환하여 Agent가 후속 작업을 할 수 있도록 해줘.
5.  **전역 변수 제거:** `RESULTS_DIR`과 같은 전역 변수 대신, 함수 인자로 출력 경로를 전달받도록 수정하여 함수의 독립성을 높여줘.

**단계별로 생각해서(Let's think step by step) `RA_code_v6.py`를 `backend/tools.py`로 리팩토링하는 코드를 작성해줘.**

---

#### **[개발 프롬프트 3/5] LangChain Agent 및 백엔드 API 개발**

**너는 시스템 컨텍스트에 정의된 시니어 소프트웨어 엔지니어이다.**

세 번째 단계로, `backend/tools.py`에서 정의한 도구들을 사용하여 LangChain Agent를 생성하고, 이 Agent와 상호작용할 수 있는 FastAPI 백엔드 서버를 구축하자.

**요구사항:**
1.  **`backend/agent_setup.py` 파일 생성:**
    - `tools.py`에서 정의한 모든 도구들을 임포트한다.
    - Google Gemini 모델 (`ChatGoogleGenerativeAI`)을 LLM으로 설정한다.
    - 대화 기록을 관리하기 위한 `ChatMessageHistory`를 설정한다.
    - ReAct 프롬프트 템플릿을 정의하여 Agent가 도구를 사용하도록 유도한다.
    - `AgentExecutor`를 생성하여 Agent를 실행할 수 있는 객체를 만든다. 이 객체는 대화 기록을 포함하여 상태를 유지해야 한다.

2.  **`backend/main.py` 파일 생성:**
    - FastAPI 애플리케이션을 초기화한다.
    - CORS 미들웨어를 설정하여 프론트엔드(Streamlit)와의 통신을 허용한다.
    - `/chat` 엔드포인트를 생성한다. 이 엔드포인트는 사용자의 메시지를 POST 요청으로 받아 `agent_setup.py`의 `AgentExecutor`를 실행하고, Agent의 응답을 JSON 형식으로 반환해야 한다.
    - `/upload` 엔드포인트를 생성한다. 이 엔드포인트는 프론트엔드에서 업로드한 데이터 파일을 서버의 `data` 폴더에 저장하고, 파일 경로를 반환해야 한다.
    - `/results/{file_name}` 엔드포인트를 생성한다. 이 엔드포인트는 `results` 폴더에 저장된 이미지 파일을 프론트엔드에 제공할 수 있도록 한다.

**단계별로 생각해서(Let's think step by step) `backend/agent_setup.py`와 `backend/main.py`의 전체 코드를 작성해줘.**

---

#### **[개발 프롬프트 4/5] Streamlit 프론트엔드 개발**

**너는 시스템 컨텍스트에 정의된 시니어 소프트웨어 엔지니어이다.**

네 번째 단계로, 사용자가 AI-Agent와 상호작용할 수 있는 Streamlit 프론트엔드를 개발하자.

**요구사항:**
1.  **`frontend/app.py` 파일 생성:**
    - **UI 구성:**
        - **사이드바:** 파일 업로더, 데이터 컬럼명 매핑 입력 필드, 상태 지시자 입력 필드, 분석 시작 버튼을 배치한다.
        - **메인 화면:** 챗봇 인터페이스를 구현한다. 사용자의 입력과 Agent의 응답이 순차적으로 표시되어야 한다.
    - **기능 구현:**
        - **파일 업로드:** 사용자가 CSV 또는 XLSX 파일을 업로드하면, 백엔드의 `/upload` 엔드포인트로 파일을 전송한다.
        - **분석 시작:** '분석 시작' 버튼을 누르면, 업로드된 파일 경로와 사용자가 설정한 컬럼 정보들을 포함한 초기 메시지를 백엔드의 `/chat` 엔드포인트로 전송하여 분석을 시작한다.
        - **챗봇 상호작용:** 사용자가 채팅 입력창에 메시지를 입력하면, `/chat` 엔드포인트로 전송하고 Agent의 응답을 받아 화면에 표시한다.
        - **결과 표시:** Agent의 응답에 테이블(Markdown)이나 이미지 경로가 포함된 경우, 이를 파싱하여 Streamlit의 `st.markdown()`과 `st.image()`를 사용해 적절히 렌더링한다. 이미지 경로는 백엔드의 `/results/` 엔드포인트를 가리키도록 구성한다.
    - **상태 관리:** Streamlit의 `st.session_state`를 사용하여 대화 기록과 현재 분석 상태(파일 경로 등)를 관리해야 한다.

**단계별로 생각해서(Let's think step by step) `frontend/app.py`의 전체 코드를 작성해줘.**

---

#### **[개발 프롬프트 5/5] 프로젝트 종합 및 실행 가이드 작성**

**너는 시스템 컨텍스트에 정의된 시니어 소프트웨어 엔지니어이다.**

마지막으로, 전체 프로젝트를 종합하고 사용자가 쉽게 실행할 수 있도록 `README.md` 파일을 작성해줘.

**요구사항:**
1.  **`README.md` 파일 생성:**
    - **프로젝트 소개:** 이 AI-Agent가 무엇을 하는지 간략히 설명한다.
    - **프로젝트 구조:** [개발 프롬프트 1/5]에서 생성한 파일 구조를 다시 한번 보여준다.
    - **설치 방법:**
        - Python 환경 설정 (가상환경 권장).
        - `pip install -r requirements.txt`를 통한 라이브러리 설치.
        - Google API 키 설정 방법 (환경 변수 `GOOGLE_API_KEY`).
    - **실행 방법:**
        - 백엔드 서버 실행 명령어 (`uvicorn backend.main:app --reload`).
        - 프론트엔드 앱 실행 명령어 (`streamlit run frontend/app.py`).
    - **사용 방법:**
        - 앱 실행 후 파일 업로드, 컬럼 정보 입력, 분석 시작, 챗봇과의 상호작용 등 기본적인 사용 흐름을 설명한다.
    - **제한 사항:** 현재 버전의 한계점이나 알려진 이슈를 명시한다.

**단계별로 생각해서(Let's think step by step) 사용자가 프로젝트를 처음부터 끝까지 성공적으로 실행할 수 있도록 명확하고 친절한 `README.md` 파일을 작성해줘.**



---
