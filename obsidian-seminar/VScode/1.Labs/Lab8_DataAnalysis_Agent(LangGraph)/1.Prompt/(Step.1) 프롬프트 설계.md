
# 생성형AI에 reliabiltiy_api_document.md 파일 업로드하고 프롬프트 실행
- 첨부파일은 python 'reliability' 패키지의 API 도움말을 markdown형식으로 정리한 자료입니다.
- 이 파일내용을 정확하게 숙지하고 이어지는 요청에 의한 결과출력 및 코딩에 활용해주세요.


---
- 다음 프롬프트 설계요구서는 'AI를 활용한 신뢰성 분석 교육'의 실습 예제로 Langchain을 이용한 연쇄추론 기능을 활용한 신뢰성 분석을 UI(Streamlit)에서 구현하기 위한 것입니다.
- 요구서의 논리성, 구체성을 검토하여 모호하거나 누락되었거나 구현의 재현성&실행가능성에 문제가 발생할 수 있는 부분을 철저하게 분석하여 개선이 필요한 항목을 제시하고, 개선방안을 제시해주세요.
- 그리고 사용자의 피드백을 받아서 프롬프트를 개선하여 한글로 제시해주세요.
  
# 프롬프트 설계요구
- [목적]
	- 우측관측중단 정보를 가진 수명데이터를 정리하고, 각각의 수명데이터를 후보분포에 적합하여 최적 분포를 결정하고, 최적 분포의 추정결과와 확률지를 시각화하고, 사용자가 원하는 신뢰성 측도(B수명, 누적고장확률)를 계산해주는 분석 에이전트 개발
	- 사용자의 요구에 따라서 각각의 분석을 독립적으로 수행할 수 있음.
	- 자동분석을 요구하는 경우 '데이터 요약 → 후보분포 적합 및 최적분포 결정 → 최적 분포 추정결과(테이블, 확률지, 신뢰성 측도:B수명, 누적고장확률) 산출 → 결과요약 보고서 작성' 을 Langchain+Langgraph로 연쇄추론하여 구현
	- UI(Streamlit) 에서 자연어를 통한 대화형으로 분석을 수행
- [요구사항]
	- 아래 제시된 프롬프팅 핵심기법에 따라서 코드를 작성할 것
	- 생성형AI에게 코드생성을 요청하는 프롬프트를 출력할 것
	- 입력데이터는 CSV 또는 XLSX 파일이며, time(시간)과 censor(관측중단여부) 컬럼을 가짐. censor 칼럼은 0은 고장, 1은 관측중단을 의미.
	- 후보분포는 와이블, 로그정규, 지수, 정규, 감마분포만을 사용하고, 최적분포는 최적분포 결정을 위해서 각 분포를 각각 개별적으로 적합시킨 후에 BIC가 가장 작은 분포로 결정합니다.
	- 신뢰성측도는 'B_p 수명'과 '시간 t에서의 누적고장확률'로 정의하고, p와 t는 사용자로부터 복수개를 입력 받습니다. 그리고 신뢰수준 100*CL(%)도 입력 받습니다.
	- 독립기능: 수명데이터 전처리&정리 기능, 최적분포 결정 기능, 분포분석 및 신뢰성 측도 계산 기능
	- 자동분석기능: '데이터 요약 → 후보분포 적합 및 최적분포 결정 → 최적 분포 추정결과(테이블, 확률지, 신뢰성 측도:B수명, 누적고장확률) 산출 → 결과요약 보고서 작성' 을 LangGraph 통해서 각각을 노드로 구현하고 연쇄추론을 통해서 분석
	- 독립기능과 자동분석기능을 도구(tools) 정의하고, LLM 모델이 사용자의 의도와 목적을 파악하여 알맞는 도구를 선택하여 실행하도록 구현
	- Streamlit의 UI는 파일 업로드, 환경설정(파일속성, 유의수준, 신뢰성측도 값), 대화창으로 구성됨
	- 대화창은 표와 구조화된 문서형태로 출력되고, 결과는 스트리밍 형식으로 출력
	- 첨부한 'reliability' 패키지의 api document 를 참조하여 분석단계별로 실제로 존재하는 함수만 사용하도록 요구할 것.
	- Fit_Everything 함수는 절대 사용하지 말 것
	- 최적분포 결정 기능과 최적분포 추정결과는 분리하여 독립적으로 구현할 것
	- B수명과 누적고장확률의 신뢰구간은 Distribution 객체의 CDF 메소드만을 사용할 것 (CI_type, CI_y, CI_x)
	- 2모수 와이블, 2모수로그정규, 지수, 2모수 정규, 2모수감마분포를 제외한 나머지 분포는 모두 제외할 것

# (참고자료) 프롬프팅 핵심기법

## **1) 역할-과업-형식 (PTF: Persona, Task, Format)**

PTF는 AI에게 지시를 내리는 가장 기본적이면서도 강력한 프레임워크입니다. AI에게 명확한 역할을 부여하면, 해당 분야의 지식과 스타일에 맞는 코드를 생성할 확률이 높아집니다.

- **P (Persona, 역할 부여):** AI의 전문 분야와 정체성을 구체적으로 지정합니다. 단순히 전문가 역할을 부여하는 것을 넘어, 사용하는 기술 스택과 전문 분야를 명시하면 더 정제된 결과물을 얻을 수 있습니다.
    
    - **예시:** "너는 **신뢰성 공학(Reliability Engineering) 전문가**이며, Python의 `pandas`, `numpy`, `matplotlib` 라이브러리를 활용한 **수명 데이터 분석(Lifetime Data Analysis)에 능숙**해."
        
- **T (Task, 과업 지시):** 수행할 작업을 구체적이고 명확하게 지시합니다. 두루뭉술한 지시 대신, 분석할 데이터의 정보(파일명, 컬럼 구조), 사용할 분석 기법 등 상세 정보를 포함해야 AI가 작업을 정확히 이해할 수 있습니다.
    
    - **예시:** "첨부된 `alt_data.csv` 파일(컬럼: `stress_level`, `time_to_failure`)을 읽어, **스트레스 수준별 와이블 분포(Weibull distribution)를 분석**하고 각 파라미터를 추정해줘."
        
- **F (Format, 형식 지정):** 결과물을 어떤 형태로 받을지 명시합니다. 코드뿐만 아니라, 보고서 초안, 함수 설명 문서(docstring), 특정 폴더 구조에 맞는 파일 목록 등 원하는 모든 출력 형식을 지정할 수 있습니다.
    
    - **예시:** "결과는 **Jupyter Notebook 형식**으로 셀을 나누어줘. 첫 번째 셀은 데이터 로딩, 두 번째 셀은 분석 코드, 세 번째 셀은 시각화 코드를 포함해줘."
        

### **2) 제로샷, 퓨샷, CoT 기법의 활용**

상황에 따라 다른 프롬프팅 기법을 선택하여 AI의 응답을 유도할 수 있습니다.

- **제로샷 프롬프팅 (Zero-Shot Prompting):** 별도의 예시 없이 바로 작업을 지시하는 방식으로, 작업이 간단하고 명확할 때 빠르게 사용하기 좋습니다.
    
    - **예시:** "파이썬으로 현재 시간을 'YYYY-MM-DD HH:MM:SS' 형식으로 출력하는 코드를 만들어줘."
        
- **퓨샷 프롬프팅 (Few-Shot Prompting):** 1~3개의 간단한 예시(입력과 출력 쌍)를 먼저 보여주고 작업을 지시합니다. AI가 내 의도를 잘 이해하지 못하거나, 특정 출력 형식을 따라 하게 만들고 싶을 때 효과적입니다. 제공하는 예시의 품질이 결과에 큰 영향을 미칩니다.
    
    - **예시:** "아래 예시처럼, 주어진 고장 코드(Failure Code)에서 시스템명만 추출하는 파이썬 함수를 만들어줘.
        
        - `F-SYS1-001` -> `SYS1`
            
        - `F-SYS2-005` -> `SYS2`"
            
- **사고의 연쇄 (CoT: Chain-of-Thought) 프롬프팅:** 복잡한 문제의 경우, AI에게 "단계별로 생각해서(Step-by-step)" 해결 과정을 설명하며 코드를 작성하도록 유도하는 기법입니다. 여러 단계를 거쳐야 하는 복잡한 분석이나 알고리즘 구현에 필수적이며, AI가 스스로 논리를 점검하게 만들어 실수를 줄일 수 있습니다.
    
    - **예시:** "총 가동 시간과 고장 횟수 데이터가 주어졌을 때, **MTBF(평균고장간격)를 계산하는 과정**을 **'단계별로 생각해서(Let's think step by step)'** 논리적으로 설명하고, 이를 수행하는 Python 코드를 작성해줘."
        

### **3) 명확한 맥락 제공 및 제약 조건 설정**

코드의 정확성과 품질을 높이기 위해 명확한 맥락과 구체적인 제약 조건을 설정하는 것이 중요합니다.

- **맥락(Context) 제공:** 분석하려는 데이터의 일부(헤더, 몇 개 행)를 직접 보여주거나, 기존 코드의 특정 부분을 제공하며 "이 코드에서 발생하는 에러를 해결해줘" 또는 "이 함수에 기능을 추가해줘"라고 지시합니다.
    
- **제약 조건(Constraints) 설정:** 사용할 프로그래밍 언어, 라이브러리 버전, 피해야 할 함수, 코드 스타일 등을 명시하여 결과물이 특정 요구사항을 만족하도록 지시합니다.
    
    - **예시:** “파이썬 3.9 버전을 기준으로, **numpy 라이브러리만 사용**해서 두 행렬의 곱을 구하는 코드를 작성해줘.”
        
- **테스트 케이스 먼저 제시하기 (TDD 방식 활용):** AI가 코드를 작성하기 전에, 통과해야 할 테스트 케이스를 먼저 제공하는 전략입니다. 이는 AI가 만들어낼 코드의 정확성과 신뢰도를 크게 향상시킵니다.
    
    - **예시:** "아래 `pytest` 형식의 **단위 테스트를 모두 통과**하는 `calculate_reliability(t, mtbf)` 함수를 작성해줘."
        
- **소프트웨어 공학 원칙 적용하기:** 소프트웨어 개발 방법론(SOLID, SRP,  클린 아키텍처, 테스트 주도 개발)을 적용할 것을 명시적으로 요구하여 모듈화되고 유지보수하기 좋은 코드를 생성하도록 유도할 수 있습니다.
    
    - **예시:** "데이터 처리, 분석, 시각화 기능을 각각 별도의 함수로 만들어줘. 각 함수는 **단일 책임 원칙(Single Responsibility Principle)을 준수**하도록 설계해줘."


---
# AI 답변
네, 제시해주신 '프롬프트 설계요구서'를 면밀히 검토했습니다. 목적과 요구사항은 명확하지만, 실제 AI가 재현 가능하고 견고한 코드를 생성하기 위해서는 몇 가지 구체화 및 논리적 보강이 필요합니다.

아래에 개선이 필요한 항목과 그에 대한 개선 방안을 제시합니다.

---

### **프롬프트 설계요구서 검토 및 개선 제안**

#### **1. 데이터 전처리 및 입력 형식의 모호성**

*   **개선 필요 항목:**
    *   "수명데이터를 정리하고"라는 표현이 모호합니다. 데이터 로딩 외에 어떤 전처리(결측치, 이상치 처리 등)를 의미하는지 불분명합니다.
    *   `reliability` 패키지의 `Fitters` 함수들은 `failures`와 `right_censored`를 별도의 리스트로 입력받습니다. 하지만 입력 파일은 `time`과 `censor` 컬럼으로 구성되어 있어, AI가 이 데이터를 어떻게 변환해야 하는지에 대한 명시적인 지침이 없습니다.

*   **개선 방안:**
    *   '데이터 정리' 단계를 '데이터 로딩 및 분리'로 구체화합니다.
    *   **명시적 지침 추가:** "업로드된 파일의 'time' 컬럼을 'censor' 컬럼의 값(0 또는 1)에 따라 `failures` 리스트와 `right_censored` 리스트로 분리하는 전처리 과정을 반드시 포함하도록 지시해야 합니다."
    *   데이터 요약 단계에서는 고장 데이터와 우측관측중단 데이터의 개수, 총 데이터 개수, 중도절단 비율 등 기본적인 통계량을 계산하여 보여주도록 구체화합니다.

#### **2. 최적 분포 결정과 분석 기능의 역할 분리 미흡**

*   **개선 필요 항목:**
    *   "최적분포 결정 기능과 최적분포 추정결과는 분리하여 독립적으로 구현할 것"이라는 요구는 좋지만, 두 기능 간의 **입력과 출력**이 명확하게 정의되지 않았습니다. 이로 인해 AI가 비효율적인 코드(예: 분포를 두 번 피팅)를 생성할 수 있습니다.

*   **개선 방안:**
    *   **역할 명확화:**
        *   **최적 분포 결정 기능 (`find_best_distribution`):** 후보 분포들을 모두 적합시켜 BIC 값을 계산하고, **최적 분포의 이름(문자열)과 각 분포의 BIC 점수를 담은 데이터프레임**을 반환하도록 역할을 명확히 합니다.
        *   **최적 분포 분석 기능 (`analyze_distribution`):** **최적 분포의 이름(문자열)을 입력**받아, 해당 분포 **하나만 다시 피팅**한 후 확률지, 신뢰성 측도 등 상세 분석 결과를 생성하도록 역할을 정의합니다. 이렇게 하면 불필요한 재계산을 방지하고 기능이 명확하게 분리됩니다.

#### **3. 신뢰성 측도 계산 방법의 구체성 부족**

*   **개선 필요 항목:**
    *   "B수명과 누적고장확률의 신뢰구간은 Distribution 객체의 CDF 메소드만을 사용할 것"이라는 제약은 매우 중요하지만, AI가 이 메소드를 어떻게 활용해야 할지 구체적인 지침이 부족합니다. `CDF` 메소드는 `CI_type`, `CI_y`, `CI_x` 등 여러 인자를 조합해야 원하는 값을 얻을 수 있기 때문입니다.

*   **개선 방안:**
    *   **구체적인 사용법 명시:**
        *   **B수명 신뢰구간:** "B_p 수명의 신뢰구간을 계산하기 위해, `distribution.CDF(CI_type='time', CI_y=p/100, CI=CL)`을 호출하여 반환되는 튜플의 첫 번째(하한)와 세 번째(상한) 값을 사용하도록 지시합니다." (p는 백분율로 입력받으므로 100으로 나눠야 함)
        *   **누적고장확률 신뢰구간:** "시간 t에서의 누적고장확률 신뢰구간을 계산하기 위해, `distribution.CDF(CI_type='reliability', CI_x=t, CI=CL)`을 호출하여 반환되는 튜플의 첫 번째(하한)와 세 번째(상한) 값을 사용하도록 지시합니다."
    *   이러한 구체적인 지침은 AI가 헤매지 않고 정확한 코드를 생성하도록 유도합니다.

#### **4. LangGraph 연쇄 추론 및 도구(Tool) 정의의 구체성 부족**

*   **개선 필요 항목:**
    *   "LangGraph 통해서 각각을 노드로 구현하고 연쇄추론을 통해서 분석"이라는 요구는 좋지만, 각 노드(Node)의 **상태(State) 전이**와 **도구(Tool)의 명세(Signature)**가 정의되지 않았습니다.
    *   사용자가 "자동분석 해줘"라고 했을 때, LLM이 어떤 도구를 어떤 순서로 호출해야 하는지에 대한 명확한 흐름이 없습니다.

*   **개선 방안:**
    *   **LangGraph 상태 정의:** 분석 과정에서 공유될 상태(State)를 명시합니다. (예: `file_path`, `failures`, `right_censored`, `summary_stats`, `bic_results`, `best_dist_name`, `analysis_results`, `final_report`)
    *   **노드(Node) 함수 명세 정의:** 각 노드가 어떤 입력을 받아 어떤 상태를 업데이트하는지 명확히 합니다.
        *   `load_and_summarize_data(state)` -> `failures`, `right_censored`, `summary_stats` 업데이트
        *   `find_best_distribution(state)` -> `bic_results`, `best_dist_name` 업데이트
        *   `analyze_best_distribution(state)` -> `analysis_results` 업데이트
        *   `generate_report(state)` -> `final_report` 업데이트
    *   **도구(Tool) 명세 정의:** LangChain 에이전트가 사용할 도구들의 함수 시그니처(입력 타입, 출력 타입, 설명)를 명확하게 정의해줍니다. 이는 LLM이 사용자의 의도에 맞는 도구를 정확히 선택하는 데 결정적인 역할을 합니다.

#### **5. UI 상호작용 및 결과 출력 방식의 구체화**

*   **개선 필요 항목:**
    *   "대화창은 표와 구조화된 문서형태로 출력"된다는 점은 좋지만, 어떤 정보가 어떤 순서로, 어떤 형식(마크다운 테이블, 코드 블록 등)으로 출력되어야 하는지에 대한 예시가 없습니다.
    *   사용자가 대화창에 자연어를 입력했을 때 분석이 시작되는지, 아니면 UI의 '분석 시작' 버튼을 눌렀을 때 시작되는지 상호작용 방식이 불분명합니다.

*   **개선 방안:**
    *   **출력 형식 예시 제공 (퓨샷 프롬프팅 활용):** 최종 보고서의 마크다운 형식 예시를 프롬프트에 포함시켜 AI가 원하는 결과물 형태를 명확히 인지하도록 합니다.
    *   **상호작용 시나리오 정의:** "사용자가 파일을 업로드하고 환경설정을 마친 후, 대화창에 '자동 분석 시작해줘'와 같은 명령어를 입력하면 `run_full_analysis` 도구가 실행되도록 구현합니다. 각 독립 기능은 '데이터 요약만 해줘'와 같은 명령어로 호출될 수 있어야 합니다." 와 같이 구체적인 시나리오를 제시합니다.

---

### **개선된 최종 프롬프트 (한글)**

위 개선 방안을 모두 반영하여, AI에게 코드 생성을 요청하기 위한 최종 프롬프트를 아래와 같이 제안합니다.

```
# 페르소나 (Persona)

당신은 Python을 사용한 신뢰성 공학 분석 전문가입니다. 특히 `reliability`, `pandas`, `numpy`, `matplotlib`, `streamlit`, `langchain`, `langgraph` 라이브러리를 활용하여 대화형 수명 데이터 분석 애플리케이션을 구축하는 데 매우 능숙합니다. 당신의 코드는 항상 모듈화되어 있으며, 단일 책임 원칙(SRP)을 준수하고, 상세한 주석과 Docstring을 포함합니다.

# 과업 (Task)

Streamlit을 사용하여 우측관측중단(right-censored) 수명 데이터를 분석하는 대화형 AI 에이전트를 개발합니다. 이 에이전트는 사용자의 자연어 요청에 따라 독립적인 분석 기능을 수행하거나, LangGraph를 이용한 연쇄 추론을 통해 전체 분석을 자동으로 수행해야 합니다.

**단계별 사고(Let's think step-by-step)를 통해 다음 요구사항을 만족하는 완전한 단일 Python 스크립트를 작성해 주세요.**

### 1. 데이터 입력 및 전처리

-   **입력 파일:** 사용자는 CSV 또는 XLSX 파일을 업로드할 수 있습니다.
-   **데이터 구조:** 파일은 `time`(수명 시간)과 `censor`(관측중단 여부) 두 개의 컬럼을 가집니다.
    -   `censor` 컬럼: `0`은 고장(failure), `1`은 우측관측중단(right-censored)을 의미합니다.
-   **전처리:** 업로드된 데이터프레임의 `time` 컬럼을 `censor` 값에 따라 `failures` 리스트와 `right_censored` 리스트로 반드시 분리해야 합니다.

### 2. 핵심 분석 로직 및 제약 조건

-   **후보 분포:** `Weibull_2P`, `Lognormal_2P`, `Exponential_1P`, `Normal_2P`, `Gamma_2P` 분포만을 사용합니다. `reliability` 패키지의 다음 함수들을 직접 호출해야 합니다:
    -   `reliability.Fitters.Fit_Weibull_2P`
    -   `reliability.Fitters.Fit_Lognormal_2P`
    -   `reliability.Fitters.Fit_Exponential_1P`
    -   `reliability.Fitters.Fit_Normal_2P`
    -   `reliability.Fitters.Fit_Gamma_2P`
-   **엄격한 제약:** **`reliability.Fitters.Fit_Everything` 함수는 절대 사용해서는 안 됩니다.**
-   **최적 분포 결정:** 각 후보 분포를 개별적으로 데이터에 적합시킨 후, **BIC(Bayesian Information Criterion) 값이 가장 작은 분포**를 최적 분포로 결정합니다.
-   **신뢰성 측도 계산:**
    -   사용자로부터 B수명을 계산할 백분율 `p` 값들(리스트), 누적고장확률을 계산할 시간 `t` 값들(리스트), 그리고 신뢰수준 `CL`(0과 1 사이의 float)을 입력받습니다.
    -   **B_p 수명 신뢰구간:** 최적 분포의 `distribution` 객체에서 `.CDF(CI_type='time', CI_y=p/100, CI=CL)` 메소드를 호출하여 시간에 대한 하한, 점추정, 상한 값을 계산합니다.
    -   **누적고장확률 신뢰구간:** 최적 분포의 `distribution` 객체에서 `.CDF(CI_type='reliability', CI_x=t, CI=CL)` 메소드를 호출하여 확률에 대한 하한, 점추정, 상한 값을 계산합니다.

### 3. 기능 구현 (LangChain Tools 및 LangGraph)

**LangChain 도구(Tools) 정의:**
사용자의 다양한 요청에 대응할 수 있도록 다음의 독립적인 기능과 자동 분석 기능을 도구로 정의합니다. 각 도구는 명확한 Docstring과 타입 힌트를 가져야 합니다.

1.  `summarize_data(failures: list, right_censored: list) -> dict`:
    -   고장 데이터와 우측관측중단 데이터의 개수, 총 데이터 개수, 중도절단 비율, 기본 통계량(평균, 표준편차, 최소, 최대)을 계산하여 딕셔너리 형태로 반환합니다.
2.  `find_best_distribution(failures: list, right_censored: list) -> dict`:
    -   모든 후보 분포를 적합시키고 BIC 값을 계산합니다.
    -   가장 작은 BIC 값을 가진 최적 분포의 이름(문자열)과 모든 후보 분포의 BIC 값을 담은 데이터프레임을 딕셔너리 형태로 반환합니다.
3.  `analyze_distribution(failures: list, right_censored: list, dist_name: str, p_values: list, t_values: list, cl: float) -> dict`:
    -   `dist_name`으로 지정된 단일 분포를 데이터에 적합시킵니다.
    -   추정된 파라미터, 신뢰구간, 적합도 통계량(BIC, AICc, AD)을 테이블로 생성합니다.
    -   Matplotlib을 사용하여 확률지(Probability Plot)를 생성하고 이미지 객체로 반환합니다.
    -   요청된 `p_values`와 `t_values`에 대한 B수명과 누적고장확률 및 신뢰구간을 계산하여 테이블로 생성합니다.
    -   이 모든 결과를 딕셔너리 형태로 반환합니다.
4.  `run_full_analysis(failures: list, right_censored: list, p_values: list, t_values: list, cl: float) -> str`:
    -   아래에 정의된 LangGraph를 실행하여 전체 분석을 자동 수행하고, 최종 요약 보고서를 마크다운 형식의 문자열로 반환합니다.

**LangGraph 연쇄 추론(Chained Reasoning) 정의:**
`run_full_analysis` 도구는 내부적으로 LangGraph를 사용하여 다음의 상태(State)와 노드(Node)로 구성된 그래프를 실행합니다.

-   **State:** `failures`, `right_censored`, `p_values`, `t_values`, `cl`, `summary_stats`, `bic_results`, `best_dist_name`, `analysis_results`, `final_report` 필드를 포함하는 `TypedDict`.
-   **Nodes:**
    1.  `summarize_data_node`: `summarize_data` 도구를 호출하여 `summary_stats` 상태를 업데이트합니다.
    2.  `find_best_distribution_node`: `find_best_distribution` 도구를 호출하여 `bic_results`와 `best_dist_name` 상태를 업데이트합니다.
    3.  `analyze_best_distribution_node`: `analyze_distribution` 도구를 호출하여 `analysis_results` 상태를 업데이트합니다.
    4.  `generate_report_node`: 모든 상태 정보를 종합하여 최종 요약 보고서를 생성하고 `final_report` 상태를 업데이트합니다.
-   **Edges:** `summarize_data_node` → `find_best_distribution_node` → `analyze_best_distribution_node` → `generate_report_node` 순서로 연결됩니다.

### 4. UI 및 출력 형식

-   **UI 구성:**
    -   **사이드바:** 파일 업로더, 신뢰수준(CL) 슬라이더, B수명(p) 및 누적고장확률(t) 입력을 위한 텍스트 입력 필드를 배치합니다.
    -   **메인 화면:** 사용자와 AI 에이전트가 상호작용하는 대화창을 구현합니다.
-   **상호작용:**
    -   사용자가 사이드바에서 파일과 파라미터를 설정한 후, 대화창에 "자동 분석 실행" 또는 "데이터 요약해줘"와 같은 자연어 명령을 입력하면, LangChain 에이전트가 의도를 파악하여 적절한 도구를 실행합니다.
-   **출력 형식 (Format):**
    -   모든 결과는 대화창에 스트리밍(streaming) 형태로 출력되어야 합니다.
    -   테이블은 마크다운 형식으로, 확률지 이미지는 `st.image()`를 사용하여 출력합니다.
    -   `run_full_analysis`의 최종 결과는 아래와 같은 구조화된 보고서 형식으로 출력되어야 합니다.

    **--- 최종 분석 보고서 예시 ---**

    ### 신뢰성 수명 데이터 분석 최종 보고서

    **1. 데이터 요약**
    | 항목 | 값 |
    | --- | --- |
    | 총 샘플 수 | 100 |
    | 고장 수 | 86 |
    | 우측관측중단 수 | 14 |
    | 중도절단 비율 | 14.0% |

    **2. 최적 분포 결정**
    가장 낮은 BIC 값을 보인 **Weibull_2P** 분포가 최적 분포로 선정되었습니다.
    | Distribution | BIC |
    | :--- | :--- |
    | Weibull_2P | 493.128 |
    | Normal_2P | 494.169 |
    | ... | ... |

    **3. 최적 분포 분석 결과 (Weibull_2P)**
    *   **추정 파라미터 (95% CI):**
        | Parameter | Point Estimate | Lower CI | Upper CI |
        | :--- | :--- | :--- | :--- |
        | Alpha | 11.2773 | 9.2134 | 13.8045 |
        | Beta | 3.30301 | 2.5895 | 4.2111 |
    *   **확률지:**
        (st.image()로 확률지 이미지 출력)

    **4. 신뢰성 측도 (95% CI)**
    *   **B-Life:**
        | p | Lower | Point | Upper |
        | :--- | :--- | :--- | :--- |
        | 10 | 4.89 | 5.78 | 6.83 |
        | 50 | 9.87 | 10.55 | 11.26 |
    *   **누적고장확률:**
        | t | Lower | Point | Upper |
        | :--- | :--- | :--- | :--- |
        | 10 | 0.412 | 0.458 | 0.504 |
        | 20 | 0.915 | 0.953 | 0.976 |

    **5. 결론 요약**
    본 분석 결과, 제공된 데이터는 Weibull 분포를 따르는 것으로 나타났습니다. B10 수명은 약 5.78 시간으로 추정되며, 20시간까지의 누적 고장 확률은 약 95.3%로 예측됩니다.
```


---
- 위 코드생성 프롬프트를 시스템 컨텍스트로 gemini.md로 저장하여, gemini cli에서 코드를 개발하고자 합니다.
- gemini cli에서 체계적으로 구현을 요구하는 작업 프롬프트를 구현 단계별로 명확하고 구체적이며 논리적&암시적&명시적 오류가 발생하지 않도록 작성해주세요. 


네, 알겠습니다. `gemini.md` 파일을 시스템 컨텍스트로 활용하여 Gemini CLI 환경에서 신뢰성 분석 AI 에이전트를 체계적으로 개발하기 위한 단계별 작업 프롬프트를 작성해 드리겠습니다.

이 프롬프트들은 각 단계가 이전 단계의 결과물(코드)을 기반으로 점진적으로 기능을 추가하는 방식으로 설계되었습니다. 이를 통해 AI는 각 작업에 집중할 수 있으며, 개발자는 단계별로 코드의 정확성을 검증할 수 있습니다.

---

### **사전 준비**

1.  이전에 생성한 **개선된 최종 프롬프트** 내용을 `gemini.md` 라는 파일 이름으로 저장합니다.
2.  터미널 또는 명령 프롬프트를 열고 다음 명령어를 사용하여 `gemini` CLI를 실행할 준비를 합니다. `gemini.md` 파일은 명령어 실행 위치와 동일한 디렉터리에 있어야 합니다.

    ```bash
    gemini --context gemini.md "첫 번째 프롬프트 내용을 여기에 입력" > app.py
    ```

---

### **Gemini CLI를 위한 단계별 작업 프롬프트**

#### **1단계: 애플리케이션 기본 구조 및 UI 셸(Shell) 생성**

*   **목표:** Streamlit 애플리케이션의 기본 골격을 만듭니다. 사용자가 파일을 업로드하고 분석 파라미터를 설정할 수 있는 사이드바와 대화 내용을 표시할 메인 화면을 구성합니다.

```text
# 프롬프트 1

시스템 컨텍스트(`gemini.md`)의 요구사항에 따라, 신뢰성 분석 AI 에이전트의 기본 UI 구조를 생성하는 전체 Python 스크립트를 작성해줘.

**요구사항:**
1.  `streamlit` 라이브러리를 사용하여 애플리케이션을 구성해줘.
2.  **사이드바 (`st.sidebar`) 구성:**
    -   파일 업로더 위젯 (`st.file_uploader`)을 추가하여 CSV 또는 XLSX 파일을 업로드할 수 있도록 해줘.
    -   신뢰수준(Confidence Level) 설정을 위한 슬라이더 (`st.slider`)를 추가해줘. (범위: 0.50 ~ 0.99, 기본값: 0.95)
    -   B수명(B-Life) 계산을 위한 백분율 `p` 값을 입력받는 텍스트 입력 (`st.text_input`)을 추가해줘. (쉼표로 여러 값 입력 가능, 예: "10, 50")
    -   누적고장확률(CDF) 계산을 위한 시간 `t` 값을 입력받는 텍스트 입력 (`st.text_input`)을 추가해줘. (쉼표로 여러 값 입력 가능, 예: "100, 500")
3.  **메인 화면 구성:**
    -   `st.title()`을 사용하여 "대화형 신뢰성 분석 AI 에이전트"라는 제목을 표시해줘.
    -   `st.session_state`를 사용하여 채팅 기록(`messages`)을 초기화하고, 이전 대화 내용을 화면에 표시하는 로직을 구현해줘.
    -   사용자 입력을 받기 위한 `st.chat_input`을 추가해줘.
4.  **초기 상태:** 아직 AI 에이전트 로직은 구현하지 말고, 사용자가 메시지를 입력하면 "아직 분석 기능이 연결되지 않았습니다."라고 응답하는 간단한 로직만 포함해줘.
```

#### **2단계: 데이터 로딩 및 전처리 기능 구현**

*   **목표:** 1단계에서 생성된 코드에 파일 업로드 처리 및 데이터 전처리 기능을 추가합니다. 이 기능은 `reliability` 패키지가 요구하는 `failures`와 `right_censored` 리스트 형식으로 데이터를 변환하는 핵심적인 역할을 합니다.

```text
# 프롬프트 2

아래에 제공된 이전 단계의 코드를 기반으로, 업로드된 파일을 읽고 신뢰성 분석에 필요한 데이터 형식으로 전처리하는 기능을 추가해줘.

**요구사항:**
1.  `load_and_preprocess_data`라는 이름의 함수를 새로 만들어줘.
    -   **입력:** Streamlit의 `UploadedFile` 객체.
    -   **처리:**
        -   `pandas`를 사용하여 CSV 또는 XLSX 파일을 데이터프레임으로 읽어줘.
        -   데이터프레임에 `time`과 `censor` 컬럼이 있는지 확인하고, 없으면 예외를 발생시켜줘.
        -   `censor` 컬럼의 값이 `0`이면 `time` 값을 `failures` 리스트에, `1`이면 `right_censored` 리스트에 추가하는 로직을 구현해줘.
    -   **출력:** `failures` 리스트와 `right_censored` 리스트를 튜플로 반환해줘.
2.  사이드바의 파일 업로더 로직을 수정하여, 파일이 업로드되면 이 함수를 호출하고 결과를 `st.session_state`에 저장하도록 구현해줘.
3.  데이터 로딩이 성공하면 "파일이 성공적으로 로드되었습니다."와 같은 확인 메시지를 화면에 표시해줘.

**[이전 단계 코드]**
```python
# 여기에 1단계에서 생성된 전체 코드를 붙여넣습니다.
```
```

#### **3단계: 독립 분석 도구(Tools) 함수 구현**

*   **목표:** LangChain 에이전트가 사용할 핵심 분석 함수들을 구현합니다. 각 함수는 명확한 입출력을 가지며, `reliability` 패키지를 사용하여 실제 계산을 수행합니다.

```text
# 프롬프트 3

아래에 제공된 이전 단계의 코드를 기반으로, LangChain 에이전트가 사용할 3개의 독립적인 분석 도구 함수를 구현해줘. 시스템 컨텍스트(`gemini.md`)의 제약 조건을 철저히 준수해야 해.

**요구사항:**
1.  **`summarize_data(failures: list, right_censored: list) -> dict` 함수 구현:**
    -   입력된 `failures`와 `right_censored` 리스트를 기반으로 데이터 요약 정보를 생성하고 딕셔너리로 반환해줘. (총 샘플 수, 고장 수, 관측중단 수, 중도절단 비율 등)
2.  **`find_best_distribution(failures: list, right_censored: list) -> dict` 함수 구현:**
    -   후보 분포(`Weibull_2P`, `Lognormal_2P`, `Exponential_1P`, `Normal_2P`, `Gamma_2P`) 각각을 `reliability.Fitters`의 해당 함수로 피팅해줘.
    -   각 분포의 BIC 값을 추출하여 데이터프레임으로 만들고, BIC가 가장 낮은 분포의 이름을 찾아줘.
    -   결과를 `{ "best_distribution_name": str, "bic_results": pd.DataFrame }` 형식의 딕셔너리로 반환해줘.
3.  **`analyze_distribution(failures: list, right_censored: list, dist_name: str, p_values: list, t_values: list, cl: float) -> dict` 함수 구현:**
    -   `dist_name`에 해당하는 분포 **하나만** 다시 피팅해줘.
    -   **파라미터 테이블:** 추정된 파라미터와 신뢰구간을 담은 데이터프레임을 생성해줘.
    -   **확률지(Probability Plot):** `matplotlib`을 사용하여 확률지를 생성하고, `io.BytesIO`를 사용해 이미지 객체로 변환해줘.
    -   **신뢰성 측도 테이블:** B수명과 누적고장확률의 점추정치 및 신뢰구간을 계산하여 각각 데이터프레임으로 생성해줘. 이때, 시스템 컨텍스트에 명시된 `.CDF()` 메소드 사용법을 정확히 따라야 해.
    -   모든 결과를 `{ "parameter_table": pd.DataFrame, "probability_plot": bytes, "b_life_table": pd.DataFrame, "cdf_table": pd.DataFrame }` 형식의 딕셔너리로 반환해줘.

**[이전 단계 코드]**
```python
# 여기에 2단계에서 생성된 전체 코드를 붙여넣습니다.
```
```

#### **4단계: LangGraph 워크플로우 정의**

*   **목표:** 3단계에서 만든 함수들을 노드로 사용하여, '자동 분석'을 위한 연쇄 추론 그래프를 LangGraph로 정의합니다.

```text
# 프롬프트 4

아래에 제공된 이전 단계의 코드를 기반으로, 자동 분석을 위한 LangGraph 워크플로우를 구현해줘.

**요구사항:**
1.  **GraphState 정의:** `TypedDict`를 사용하여 분석 과정에서 공유될 상태(State)를 정의해줘. 상태에는 `failures`, `right_censored`, `summary_stats`, `bic_results`, `best_dist_name`, `analysis_results`, `final_report` 등이 포함되어야 해.
2.  **노드(Node) 함수 정의:**
    -   `summarize_data_node`, `find_best_distribution_node`, `analyze_best_distribution_node`를 각각 정의해줘. 각 노드는 상태(state)를 입력받아 3단계에서 만든 해당 도구 함수를 호출하고, 그 결과를 상태에 업데이트하여 반환해야 해.
    -   `generate_report_node`를 정의해줘. 이 노드는 모든 분석 결과를 종합하여 시스템 컨텍스트에 제시된 예시와 같은 형식의 마크다운 보고서를 생성하고, 상태의 `final_report` 필드를 업데이트해야 해.
3.  **그래프(Graph) 빌드:**
    -   `StatefulGraph`를 생성하고 정의된 노드들을 추가해줘.
    -   `set_entry_point`와 `add_edge`를 사용하여 `summarize_data` -> `find_best_distribution` -> `analyze_best_distribution` -> `generate_report` 순서로 노드를 연결해줘.
    -   마지막으로 그래프를 `compile()` 해줘.

**[이전 단계 코드]**
```python
# 여기에 3단계에서 생성된 전체 코드를 붙여넣습니다.
```
```

#### **5단계: LangChain 에이전트 생성 및 도구 통합**

*   **목표:** 3단계의 독립 도구들과 4단계의 LangGraph 워크플로우를 하나의 에이전트로 통합합니다. 이 에이전트는 사용자의 자연어 입력을 해석하여 가장 적절한 도구를 선택하고 실행하는 역할을 합니다.

```text
# 프롬프트 5

아래에 제공된 이전 단계의 코드를 기반으로, 모든 분석 기능을 통합하는 LangChain 에이전트를 생성해줘.

**요구사항:**
1.  **`run_full_analysis` 도구 함수 정의:**
    -   이 함수는 4단계에서 생성한 LangGraph 워크플로우를 실행하는 역할을 해.
    -   입력으로 `failures`, `right_censored`, `p_values`, `t_values`, `cl`을 받고, 그래프를 실행한 후 최종 보고서 문자열을 반환하도록 구현해줘.
2.  **도구 리스트 생성:**
    -   `summarize_data`, `find_best_distribution`, `analyze_distribution`, 그리고 새로 만든 `run_full_analysis` 함수를 `Tool` 객체로 변환하여 리스트에 담아줘.
3.  **에이전트 생성:**
    -   `ChatPromptTemplate`을 사용하여 시스템 메시지와 사용자 입력을 처리하는 프롬프트를 정의해줘.
    -   Gemini 모델에 도구들을 바인딩(`bind_tools`)하고, 프롬프트와 모델을 파이프라인으로 연결하여 `AgentExecutor`를 생성해줘.

**[이전 단계 코드]**
```python
# 여기에 4단계에서 생성된 전체 코드를 붙여넣습니다.
```
```

#### **6단계: Streamlit UI와 LangChain 에이전트 최종 통합**

*   **목표:** 모든 구성 요소를 결합하여 완전한 대화형 애플리케이션을 완성합니다. 사용자의 입력을 받아 에이전트를 실행하고, 그 결과를 스트리밍 방식으로 화면에 아름답게 출력합니다.

```text
# 프롬프트 6

이제 마지막 단계야. 아래에 제공된 이전 단계의 코드를 기반으로, Streamlit UI와 LangChain 에이전트를 완전히 통합해줘.

**요구사항:**
1.  **Streamlit 채팅 로직 수정:**
    -   사용자가 `st.chat_input`에 메시지를 입력하면, `st.session_state`에 저장된 데이터 및 설정값과 함께 메시지를 5단계에서 생성한 `AgentExecutor`에 전달하도록 로직을 수정해줘.
2.  **결과 처리 및 출력:**
    -   에이전트의 응답을 스트리밍으로 받아 `st.write_stream`을 사용해 대화창에 표시해줘.
    -   에이전트가 도구를 호출하여 반환한 결과(딕셔너리)를 파싱하는 로직을 추가해줘.
    -   결과에 `parameter_table`이나 `bic_results`와 같은 데이터프레임이 있으면 `st.dataframe()` 또는 `st.markdown()`으로 출력해줘.
    -   결과에 `probability_plot` 이미지가 있으면 `st.image()`로 출력해줘.
    -   `run_full_analysis`가 반환한 최종 보고서는 `st.markdown()`을 사용하여 구조화된 문서 형태로 출력해줘.
3.  **전체 코드 완성:** 모든 기능을 포함하는 최종 `app.py` 스크립트를 완성해줘.

**[이전 단계 코드]**
```python
# 여기에 5단계에서 생성된 전체 코드를 붙여넣습니다.
```
```